{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wslock/D012513A-Specialised-Bio-informatics-Machine-Learning/blob/main/practicum_I/Splice_Site_Prediction_Solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-MyLGyTxLx6G"
      },
      "outputs": [],
      "source": [
        "import warnings;\n",
        "warnings.filterwarnings('ignore');\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO24y4Jju21u"
      },
      "source": [
        "# Splice site prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhcU9Uucu21v"
      },
      "source": [
        "Gene splicing is a post-transcriptional modification in which a single gene can code for multiple proteins. Gene Splicing is done in eukaryotes, prior to mRNA translation, by the differential inclusion or exclusion of regions of pre-mRNA. Gene splicing is an important source of protein diversity.\n",
        "\n",
        "The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: \"GT\" for donor and \"AG\" for acceptor sites. In this project you will fit a classification model for acceptor splice site prediction in DNA sequences.\n",
        "\n",
        "This model will consider each AG in the DNA as a candidate acceptor site, extract a local context surrounding the candidate acceptor site, represent the candidate site as a feature vector and the predict the class ('acceptor site' or 'not acceptor site') by applying the model in the constructed feature vector.\n",
        "\n",
        "The folder that contains the annotated acceptor site data is on GitHub at the following location:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xrdBiQtAu21v"
      },
      "outputs": [],
      "source": [
        "data_location = \"https://raw.githubusercontent.com/sdgroeve/D012513A-Specialised-Bio-informatics-Machine-Learning/main/practicum_I/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipJV7FSYLx6L"
      },
      "source": [
        "The dataset we will use for fitting (training) our predictive model can be found in this comma-separated `.csv` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bDt-FF8jLx6L"
      },
      "outputs": [],
      "source": [
        "data_name = \"acceptor_site_dataset.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZazEnk_Lx6M"
      },
      "source": [
        "Read this `.csv` file from the `data_location` folder into a Pandas DataFrame called `data`: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kZin_QP1Lx6M"
      },
      "outputs": [],
      "source": [
        "###Start code here\n",
        "\n",
        "data = pd.read_csv(data_location+data_name)\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blncvRsHoaTo"
      },
      "source": [
        "The dataset we will use for fitting (training) our predictive model can be found in this comma-separated `.csv` file:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz9fxtXRLx6N"
      },
      "source": [
        "Print the first 5 rows in `data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_lJt4Vopu212",
        "outputId": "6caab9cf-4ebe-4dd6-f6c6-a01c9df92fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 sequence  label subset\n",
            "0  TTTGAATTGTAGGTGTCCTGCT      1  train\n",
            "1  TATTTTTTAAAGAACTGGAAGA      1  train\n",
            "2  TTTCTTTTTCAGATGAAGAATG      1  train\n",
            "3  TATTAATTTCAGTTTGGTTGTT      1  train\n",
            "4  TAAAAATTTAAGTTCGTCCCGA      1  train\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "print(data.iloc[0:5])\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgIExxtu216"
      },
      "source": [
        "We can see that there are three columns in the dataset. \n",
        "\n",
        "The column `sequence` contains the local context DNA sequence. The nucleotide positions 11 and 12 in the sequence are the candidate acceptor site and have value \"A\" and \"G\" for all rows in the dataset. The local context consists of 10 nucleotides upstream en 10 nucleotides downstream the candidate acceptor site. \n",
        "\n",
        "The column `label` contains the class of the candidate acceptor site: 1 for \"is acceptor site\" and 0 for \"is not acceptor site\". \n",
        "\n",
        "The column `subset` indicates if the row (instance) is part of the trainset or the testset.\n",
        "\n",
        "Use the Pandas DataFrame `value_counts()` summary function to print the number of instances in the trainset and the testset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PYhNkKz3u217",
        "outputId": "b7b85ed9-8174-4da2-ae56-55974596b179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    2752\n",
              "test      552\n",
              "Name: subset, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "###Start code here\n",
        "data.subset.value_counts()\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teweqTUhu21_"
      },
      "source": [
        "To fit a logistic regression model on the trainset we need to represent the local context DNA sequence as a numerical feature vector suitable for model fitting. This process is known as **feature engineering**. \n",
        "\n",
        "The \"AG\" dinucleotide in the middle of each local context sequence is the same for both classes, i.e. it does not provide any discriminative information. So, there is no rational behind computing features from this part of the local context sequence.\n",
        "\n",
        "Use the Pandas DataFrame `map()` method to remove the middle \"AG\" dinucleotides in the DNA sequences (don't create a new column):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Bb6NTDWxLx6P",
        "outputId": "e0f0dd09-6c92-4a54-9214-33ed2d03cef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 sequence  label subset\n",
            "0  TTTGAATTGTAGGTGTCCTGCT      1  train\n",
            "1  TATTTTTTAAAGAACTGGAAGA      1  train\n",
            "2  TTTCTTTTTCAGATGAAGAATG      1  train\n",
            "3  TATTAATTTCAGTTTGGTTGTT      1  train\n",
            "4  TAAAAATTTAAGTTCGTCCCGA      1  train\n",
            "               sequence  label subset\n",
            "0  TTTGAATTGTGTGTCCTGCT      1  train\n",
            "1  TATTTTTTAAAACTGGAAGA      1  train\n",
            "2  TTTCTTTTTCATGAAGAATG      1  train\n",
            "3  TATTAATTTCTTTGGTTGTT      1  train\n",
            "4  TAAAAATTTATTCGTCCCGA      1  train\n"
          ]
        }
      ],
      "source": [
        "print(data.head())\n",
        "\n",
        "###Start code here\n",
        "data.sequence = data.sequence.map(lambda p : p[:10] + p[-10:])\n",
        "###End code here\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZkQumNiu22E"
      },
      "source": [
        "Next, we create a feature for each of the nucleotide positions in the local context DNA sequence.\n",
        "\n",
        "The [pandas.Series.str.split](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) function splits a string in a column (pandas.Series) from the beginning, at the specified delimiter string.\n",
        "\n",
        "I use this function to split the `sequence` column into one column for each nucleotide position. I also rename the resulting columns to better relfect their meaning: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "B1IGFl3dLx6R",
        "outputId": "494978bd-a8cd-4b02-a73b-67dac1e5f7c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     -10 -9 -8 -7 -6 -5 -4 -3 -2 -1  1  2  3  4  5  6  7  8  9 10\n",
            "0      T  T  T  G  A  A  T  T  G  T  G  T  G  T  C  C  T  G  C  T\n",
            "1      T  A  T  T  T  T  T  T  A  A  A  A  C  T  G  G  A  A  G  A\n",
            "2      T  T  T  C  T  T  T  T  T  C  A  T  G  A  A  G  A  A  T  G\n",
            "3      T  A  T  T  A  A  T  T  T  C  T  T  T  G  G  T  T  G  T  T\n",
            "4      T  A  A  A  A  A  T  T  T  A  T  T  C  G  T  C  C  C  G  A\n",
            "...   .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n",
            "3299   T  T  T  G  A  A  G  T  T  T  C  T  T  C  C  T  T  C  T  C\n",
            "3300   C  T  G  C  T  A  A  T  A  T  T  G  A  C  A  G  C  A  A  T\n",
            "3301   T  T  C  C  A  A  A  T  A  T  G  A  A  A  A  T  C  G  A  A\n",
            "3302   A  A  A  A  T  G  T  C  G  C  A  A  C  A  A  C  A  A  G  A\n",
            "3303   A  G  A  A  G  T  A  T  G  G  G  T  G  G  A  A  T  G  T  T\n",
            "\n",
            "[3304 rows x 20 columns]\n"
          ]
        }
      ],
      "source": [
        "data_features = data['sequence'].str.split('', expand=True).iloc[:,1:21]\n",
        "data_features.columns = [\"%i\"%i for i in range(-10,0,1)] + [\"%i\"%i for i in range(1,11,1)]\n",
        "\n",
        "print(data_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF35D-gbLx6R"
      },
      "source": [
        "Next you will map each of the nucleotides to a numerical value. Create a Python function `map_nucleotide_to_number()` that maps nucleotides A, C, G and T to 0, 1, 2 and 3 respectively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "N9nsz212Lx6S",
        "outputId": "d72b1829-1fd6-4615-88cd-125395d7eadf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function works for nucleotide A\n",
            "Function works for nucleotide C\n",
            "Function works for nucleotide G\n",
            "Function works for nucleotide T\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "\n",
        "def map_nucleotide_to_number(x):\n",
        "  if x == 'A':\n",
        "    mapped_number = 0\n",
        "  elif x == 'C':\n",
        "    mapped_number = 1 \n",
        "  elif x == 'G':\n",
        "    mapped_number = 2\n",
        "  elif x == 'T':\n",
        "    mapped_number = 3\n",
        "  return(mapped_number)\n",
        "\n",
        "###End code here\n",
        "\n",
        "for nucleotide, mapped_number in zip(['A','C','G','T'],range(4)):\n",
        "    if map_nucleotide_to_number(nucleotide) != mapped_number:\n",
        "        print(\"Function is not working for nucleotide %s\"%nucleotide)\n",
        "    else:\n",
        "        print(\"Function works for nucleotide %s\"%nucleotide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxkHHWH3Lx6S"
      },
      "source": [
        "You have seen the Pandas DataFrame functions `map()` and `apply()`. Similar to these functions, there is also the function `applymap()` that applies a function to every element of a DataFrame.\n",
        "\n",
        "Apply the `map_nucleotide_to_number()` you created to every element in the `data_features` DataFrame (write the resulting DataFrame to `data_features_numerical`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DXUwBQiNLx6T",
        "outputId": "ecbb200b-0b56-45aa-ee25-9de220844a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      -10  -9  -8  -7  -6  -5  -4  -3  -2  -1  1  2  3  4  5  6  7  8  9  10\n",
            "0       3   3   3   2   0   0   3   3   2   3  2  3  2  3  1  1  3  2  1   3\n",
            "1       3   0   3   3   3   3   3   3   0   0  0  0  1  3  2  2  0  0  2   0\n",
            "2       3   3   3   1   3   3   3   3   3   1  0  3  2  0  0  2  0  0  3   2\n",
            "3       3   0   3   3   0   0   3   3   3   1  3  3  3  2  2  3  3  2  3   3\n",
            "4       3   0   0   0   0   0   3   3   3   0  3  3  1  2  3  1  1  1  2   0\n",
            "...   ...  ..  ..  ..  ..  ..  ..  ..  ..  .. .. .. .. .. .. .. .. .. ..  ..\n",
            "3299    3   3   3   2   0   0   2   3   3   3  1  3  3  1  1  3  3  1  3   1\n",
            "3300    1   3   2   1   3   0   0   3   0   3  3  2  0  1  0  2  1  0  0   3\n",
            "3301    3   3   1   1   0   0   0   3   0   3  2  0  0  0  0  3  1  2  0   0\n",
            "3302    0   0   0   0   3   2   3   1   2   1  0  0  1  0  0  1  0  0  2   0\n",
            "3303    0   2   0   0   2   3   0   3   2   2  2  3  2  2  0  0  3  2  3   3\n",
            "\n",
            "[3304 rows x 20 columns]\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "\n",
        "data_features_numerical = data_features.applymap(lambda p : map_nucleotide_to_number(p))\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(data_features_numerical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5HDyi7uLx6T"
      },
      "source": [
        "Finally, I contruct the trainset and testset feature vectors based on the `subset` column in `data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ja6_S7o-Lx6T"
      },
      "outputs": [],
      "source": [
        "X_train = data_features_numerical.loc[data.subset == \"train\"]\n",
        "X_test = data_features_numerical.loc[data.subset == \"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55UHDdrGLx6U"
      },
      "source": [
        "Create Pandas Series `y_train` and `y_test` that contain the classes for the DataFrames `X_train` and `X_test` respectively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pNwu1KE2Lx6U"
      },
      "outputs": [],
      "source": [
        "###Start code here\n",
        "\n",
        "Y_train = data.label.loc[data.subset == \"train\"]\n",
        "Y_test = data.label.loc[data.subset == \"test\"]\n",
        "\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFSP3h88Lx6U"
      },
      "source": [
        "How many instances of class '0' are there in the trainset? How many of class '1'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Z73Vhp-WLx6U",
        "outputId": "9f2d5ff9-99f3-413f-8b6e-16bde14cd73f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2497\n",
              "1     255\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "###Start code here\n",
        "Y_train.value_counts()\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0acfNaLx6V"
      },
      "source": [
        "How many instances of class '0' are there in the testset? How many of class '1'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "glKAO3ZJLx6V",
        "outputId": "0689b5b1-9ab5-449f-8c8e-459094e9853e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    497\n",
              "1     55\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "###Start code here\n",
        "Y_test.value_counts()\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0573K2rRu22W"
      },
      "source": [
        "Initialize the `LogisticRegression` model from `sklearn.linear_model`: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "W_QpEOrTLx6W",
        "outputId": "4df85930-294f-4ff6-8628-1538a6423a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression()\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "###Start code here\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(lr_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYPXoNvzLx6W"
      },
      "source": [
        "Fit the logistic regression model `lr_ model` on the trainset `X_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Hip_AJBALx6W",
        "outputId": "ed9ab3f7-1e22-43fc-825e-622793d3c6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "###Start code here\n",
        "lr_model.fit(X_train, Y_train)\n",
        "###End code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMquhGBaLx6X"
      },
      "source": [
        "Compute class predictions for the testset `X_test`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "eQoU1Q9mLx6X",
        "outputId": "2cb7a9a6-c7c1-4d56-d770-5def98872477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "\n",
        "predictions = lr_model.predict(X_test)\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46fTft9BLx6X"
      },
      "source": [
        "Use the `accuracy_score()` function in `sklearn.metrics` to compute the accuracy of the predictions on the testset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "jc7J8SrIu22X",
        "outputId": "d9e6e9ff-223e-423b-c108-1a730a6c29fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9202898550724637\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "###Start code here\n",
        "\n",
        "score_acc = metrics.accuracy_score(Y_test, predictions)\n",
        "\n",
        "###Start code here\n",
        "\n",
        "print(score_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPu8YDA2u23D"
      },
      "source": [
        "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class '0' for all test points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "5kV1yMLOu23E",
        "outputId": "71400f2e-56fa-46fe-8634-cd1a30106f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "predictions_zero = [0]*len(y_test)\n",
        "print(predictions_zero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efNP_I-Ju23I"
      },
      "source": [
        "What is the accuracy of these predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "fmdBsSaou23K",
        "outputId": "470a27e5-08a8-4fc1-a2b1-96a7a5f62522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9003623188405797\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "\n",
        "score_acc = metrics.accuracy_score(Y_test, predictions_zero)\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(score_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lZ3nJUPu23P"
      },
      "source": [
        "So this should be a good score as well, even though the model did not learn anything.\n",
        "\n",
        "For classification tasks where the classes are highly imbalanced, accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% \"AG\" dinucleotides in a genome that are true acceptor sites then a model that predicts class '0' for each \"AG\" would have an accuracy of 99.9%.\n",
        "\n",
        "You have seen how a ROC curve plots the true positive rate against the false positive rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. \n",
        "\n",
        "To transform a ROC curve into one metric we can use the area under the curve (AUC). This metric can be computed with the `roc_auc_score()` function in `sklearn.metrics`. \n",
        "\n",
        "What is the AUC score of the predictions computed on the testset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nTjM_o7Iu23Q",
        "outputId": "41904d69-8fa7-4839-b0df-d2e73b3d6a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6970184744832632\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "###Start code here\n",
        "\n",
        "score_auc = roc_auc_score(Y_test, predictions)\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtsruwQSLx6a"
      },
      "source": [
        "Now, let's print the predictions again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "9TyPfILnLx6a",
        "outputId": "396cac18-c02e-41ae-c6c7-a6e831fd69dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1\n",
            " 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbuR3_0Uu23V"
      },
      "source": [
        "These are predicted classes.\n",
        "\n",
        "To compute the AUC, we actually need these predictions to be scores (a continuous value).\n",
        "\n",
        "For logistic regression these scores are the class probabilities predicted by the model (a value between 0 and 1). \n",
        "\n",
        "We can obtain these scores with the `predict_proba()` function of the `LogisticRegression` module as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "xMT2X0i7u23W",
        "outputId": "b4949cd4-d671-4987-db67-70661c6c24ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       prob_0    prob_1\n",
            "0    0.327520  0.672480\n",
            "1    0.425903  0.574097\n",
            "2    0.341907  0.658093\n",
            "3    0.999413  0.000587\n",
            "4    0.942077  0.057923\n",
            "..        ...       ...\n",
            "547  0.823318  0.176682\n",
            "548  0.996326  0.003674\n",
            "549  0.997360  0.002640\n",
            "550  0.984624  0.015376\n",
            "551  0.970995  0.029005\n",
            "\n",
            "[552 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "predictions = pd.DataFrame(lr_model.predict_proba(X_test),columns=[\"prob_0\",\"prob_1\"])\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecMykZJcu23h"
      },
      "source": [
        "The first and second column contain the predicted probabilities for class '0' and '1' respectively. To compute the AUC we need to use the class probabilities of class '1'. \n",
        "\n",
        "Compute the AUC from the class probabilities of class '1' computed from the testset: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "k7Zj60JBu23i",
        "outputId": "648ee2ea-0d6d-4f61-e110-6fd9965d3903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.897969635997805\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "\n",
        "score_auc = roc_auc_score(Y_test, predictions.prob_1)\n",
        "\n",
        "###End code here\n",
        "\n",
        "print(score_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EudhUPu-u23o"
      },
      "source": [
        "Is this good generalization performance?\n",
        "\n",
        "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering (the columns are not ordinal features). \n",
        "\n",
        "It is better to transform a categorical feature into one binary feature for each category. This is known as [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). \n",
        "\n",
        "We can create a one-hot encoded feature vector of categorical feature columns using the Pandas function `get_dummies()` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "TFZGymYTLx6b",
        "outputId": "93e99f3d-e7bb-4585-de20-5f480a48678f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      -10_A  -10_C  -10_G  -10_T  -9_A  -9_C  -9_G  -9_T  -8_A  -8_C  ...  \\\n",
            "0         0      0      0      1     0     0     0     1     0     0  ...   \n",
            "1         0      0      0      1     1     0     0     0     0     0  ...   \n",
            "2         0      0      0      1     0     0     0     1     0     0  ...   \n",
            "3         0      0      0      1     1     0     0     0     0     0  ...   \n",
            "4         0      0      0      1     1     0     0     0     1     0  ...   \n",
            "...     ...    ...    ...    ...   ...   ...   ...   ...   ...   ...  ...   \n",
            "3299      0      0      0      1     0     0     0     1     0     0  ...   \n",
            "3300      0      1      0      0     0     0     0     1     0     0  ...   \n",
            "3301      0      0      0      1     0     0     0     1     0     1  ...   \n",
            "3302      1      0      0      0     1     0     0     0     1     0  ...   \n",
            "3303      1      0      0      0     0     0     1     0     1     0  ...   \n",
            "\n",
            "      8_G  8_T  9_A  9_C  9_G  9_T  10_A  10_C  10_G  10_T  \n",
            "0       1    0    0    1    0    0     0     0     0     1  \n",
            "1       0    0    0    0    1    0     1     0     0     0  \n",
            "2       0    0    0    0    0    1     0     0     1     0  \n",
            "3       1    0    0    0    0    1     0     0     0     1  \n",
            "4       0    0    0    0    1    0     1     0     0     0  \n",
            "...   ...  ...  ...  ...  ...  ...   ...   ...   ...   ...  \n",
            "3299    0    0    0    0    0    1     0     1     0     0  \n",
            "3300    0    0    1    0    0    0     0     0     0     1  \n",
            "3301    1    0    1    0    0    0     1     0     0     0  \n",
            "3302    0    0    0    0    1    0     1     0     0     0  \n",
            "3303    1    0    0    0    0    1     0     0     0     1  \n",
            "\n",
            "[3304 rows x 80 columns]\n"
          ]
        }
      ],
      "source": [
        "data_features_onehot_encoding = pd.get_dummies(data_features)\n",
        "\n",
        "print(data_features_onehot_encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG9A9oIKLx6c"
      },
      "source": [
        "What it the AUC on the testset for a model fitted on these one-hot encoded feature vectors in the trainset? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "tnYXdrQ5Lx6c",
        "outputId": "094b7dbf-22ba-4f7c-dc6f-c35b92168a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9313334552771172\n"
          ]
        }
      ],
      "source": [
        "###Start code here\n",
        "X_train = data_features_onehot_encoding.loc[data.subset == \"train\"]\n",
        "X_test = data_features_onehot_encoding.loc[data.subset == \"test\"]\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, Y_train)\n",
        "predictions = lr_model.predict(X_test)\n",
        "score_auc = roc_auc_score(Y_test, predictions)\n",
        "###End code here\n",
        "\n",
        "print(score_auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wRe1CLnUu24l"
      },
      "source": [
        "Do you observe better AUC for the one-hot encoded feature vectors?\n",
        "\n",
        "In scikit-learn a fitted logistic regression model has the fitted modelparameter values stored in `.coef_[0]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8f-NBEUt4AjE",
        "outputId": "fb127923-60b0-4733-8255-1c6714dd2325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.18535922 -0.17254465 -0.64432076  0.63155105  0.36323346  0.09664242\n",
            " -0.82511475  0.36528374  0.42644274 -0.00627464 -1.01475009  0.59462685\n",
            "  0.2943751  -0.68264436 -0.36023434  0.74854847  0.62222768 -1.22208009\n",
            " -0.13600194  0.73589922  0.10617957  0.17511685 -0.97650548  0.69525393\n",
            " -0.30416484 -0.40788395 -1.10386006  1.81595372 -0.21790803 -1.20477227\n",
            " -1.11330282  2.53602798  0.0671242  -0.15447455 -1.36278366  1.45017887\n",
            " -0.6199823   2.10008164 -1.93416747  0.454113    0.31268108 -0.83265987\n",
            "  1.45490251 -0.93487886 -0.35797043  0.26184045 -0.08013915  0.17631399\n",
            " -0.0247569   0.23742285  0.40959851 -0.6222196  -0.31194619  0.29535498\n",
            "  0.42828426 -0.41164818 -0.20320261  0.19427966  0.3345353  -0.32556748\n",
            " -0.30042054  0.66079598  0.26838713 -0.62871771 -0.20485503  0.36583118\n",
            "  0.2601907  -0.42112198 -0.24838684  0.44239752  0.33979426 -0.53376007\n",
            " -0.21496153  0.00264659  0.35339661 -0.1410368  -0.69564289  0.42731881\n",
            "  0.38151408 -0.11314514]\n"
          ]
        }
      ],
      "source": [
        "print(lr_model.coef_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPAICuc4NWT"
      },
      "source": [
        "For logistic regression this is one modelparameter for each feature (plus the interecept, which is not in `.coef_[0]`). \n",
        "\n",
        "Recall that for logistic regression a prediction is made by multiplying each fitted modelparameter with the corresponding feature, summing them and then squeezing this sum between 0 and 1 with the logistic function. \n",
        "\n",
        "Since all features have values 0 or 1, the modelparameter values indicate the contribution (importance) of a feature during prediction.\n",
        "\n",
        "The following code creates a Pandas DataFrame `model_parameters` with two columns: `feature` that is the name of the feature that the modelparameter is associated with, and `parameter_value` that is the value of the fitted modelparameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "rY2jtt1gLx6d",
        "outputId": "c026de6b-3abf-485e-d7b4-92926f1161b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   feature  parameter_value\n",
            "0    -10_A         0.185359\n",
            "1    -10_C        -0.172545\n",
            "2    -10_G        -0.644321\n",
            "3    -10_T         0.631551\n",
            "4     -9_A         0.363233\n",
            "..     ...              ...\n",
            "75     9_T        -0.141037\n",
            "76    10_A        -0.695643\n",
            "77    10_C         0.427319\n",
            "78    10_G         0.381514\n",
            "79    10_T        -0.113145\n",
            "\n",
            "[80 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "model_parameters = pd.DataFrame()\n",
        "model_parameters[\"feature\"] = data_features_onehot_encoding.columns\n",
        "model_parameters[\"parameter_value\"] = lr_model.coef_[0]\n",
        "print(model_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7o9tUmLx6d"
      },
      "source": [
        "A Pandas DataFrame also has functions to [plot the data](https://pandas.pydata.org/docs/user_guide/visualization.html). Here I plot the modelparameter values as a bar chart:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "EEEgAeMCLx6d",
        "outputId": "b34acc90-890b-4c4c-ec4d-04fdc65458e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfd2e22cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x864 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model_parameters.plot.bar(x=\"feature\",y=\"parameter_value\",figsize=(20,12))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_W6oyVILx6e"
      },
      "source": [
        "What are the most important one-hot encoded features for the fitted logistic regression model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8JC6INLx6e"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "2.1._Classification_solutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}